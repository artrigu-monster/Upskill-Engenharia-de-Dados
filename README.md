# Pipeline de Dados: An√°lise de Lan√ßamentos da SpaceX

![Databricks](https://img.shields.io/badge/Databricks-FF3621?style=for-the-badge&logo=databricks&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![PySpark](https://img.shields.io/badge/PySpark-002D5E?style=for-the-badge&logo=apache-spark&logoColor=white)
![Delta Lake](https://img.shields.io/badge/Delta_Lake-00435A?style=for-the-badge&logo=linux&logoColor=white)

## üéØ Objetivo do Projeto

Este projeto implementa um pipeline de dados ETL (Extra√ß√£o, Transforma√ß√£o e Carga) de ponta a ponta, desenvolvido como parte do programa **Upskill Tiller | Engenharia de Dados**.

O objetivo principal √© consumir dados de duas APIs p√∫blicas distintas, enriquec√™-los e model√°-los para criar um dataset anal√≠tico de alta qualidade. O caso de uso escolhido foi a **an√°lise de lan√ßamentos de foguetes da SpaceX**, enriquecendo os dados brutos com informa√ß√µes demogr√°ficas e geogr√°ficas dos pa√≠ses onde as bases de lan√ßamento est√£o localizadas.

O resultado final √© uma tabela Delta Lake limpa e otimizada, al√©m de todos os artefatos de an√°lise (relat√≥rio de qualidade e gr√°ficos) gerados de forma 100% automatizada pelo pipeline.

## üõ†Ô∏è Tecnologias Utilizadas

* **Plataforma Cloud:** Databricks Community Edition
* **Linguagem:** Python
* **Processamento de Dados:** PySpark
* **Formato de Armazenamento:** Delta Lake (Tabela Gerenciada)
* **Bibliotecas Python:** `requests`, `pandas`, `matplotlib`, `seaborn`
* **Versionamento:** Git & GitHub

## üìÇ Estrutura do Reposit√≥rio

Ao executar o pipeline, a seguinte estrutura de artefatos √© gerada dentro do reposit√≥rio no Databricks, pronta para ser sincronizada com o GitHub.

```
/
‚îú‚îÄ‚îÄ README.md           # Documenta√ß√£o do projeto
‚îú‚îÄ‚îÄ requirements.txt    # Depend√™ncias Python
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ pipeline_launches.ipynb # Notebook com o c√≥digo do pipeline
‚îî‚îÄ‚îÄ output/
    ‚îú‚îÄ‚îÄ dq_report/
    ‚îÇ   ‚îî‚îÄ‚îÄ dq_report.json  # Relat√≥rio de qualidade dos dados (gerado)
    ‚îî‚îÄ‚îÄ images/
        ‚îú‚îÄ‚îÄ launches_per_year.png       # Gr√°fico de lan√ßamentos por ano (gerado)
        ‚îú‚îÄ‚îÄ launches_per_country.png    # Gr√°fico de lan√ßamentos por pa√≠s (gerado)
        ‚îî‚îÄ‚îÄ launches_per_launchpad.png  # Gr√°fico de lan√ßamentos por base (gerado)
```

## üìà Etapas do Pipeline

O pipeline foi desenvolvido no notebook `pipeline_launches.ipynb` e segue as seguintes etapas:

1.  **Extra√ß√£o (E):**
    * Consumo de dados da **SpaceX API** e da **REST Countries API**.
    * Implementado tratamento de erros robusto para garantir a resili√™ncia do pipeline contra falhas de API (timeouts, erros HTTP).

2.  **Transforma√ß√£o (T):**
    * Limpeza, padroniza√ß√£o de tipos e sele√ß√£o de colunas relevantes.
    * **Enriquecimento de Dados:** Cria√ß√£o da coluna `country` (pa√≠s) para as bases de lan√ßamento, que n√£o era fornecida pela API.
    * **Join Estrat√©gico:** Cruzamento dos dados de lan√ßamentos com os dados dos pa√≠ses para criar um dataset unificado.

3.  **Carga (L) e Gera√ß√£o de Artefatos:**
    * **Relat√≥rio de Qualidade:** Gera√ß√£o autom√°tica de um arquivo `dq_report.json` com m√©tricas essenciais.
    * **Persist√™ncia Otimizada:** Salvamento do DataFrame final como uma **tabela Delta gerenciada** no Databricks, particionada por ano e m√™s para otimizar consultas.
    * **Gera√ß√£o de Gr√°ficos:** Cria√ß√£o e salvamento autom√°tico de todas as visualiza√ß√µes de an√°lise como arquivos `.png` usando Matplotlib e Seaborn.

## üöÄ Como Executar no Databricks

1.  **Configurar o Cluster:** Crie ou utilize um cluster Databricks.
2.  **Clonar o Reposit√≥rio:**
    * Na interface do Databricks, v√° para a se√ß√£o **Repos**.
    * Clique em **"Add Repo"** e cole a URL deste reposit√≥rio.
3.  **Abrir o Notebook:** Navegue at√© `notebooks/pipeline_launches.ipynb` e anexe-o ao seu cluster.
4.  **Executar o Pipeline:** Execute todas as c√©lulas em ordem (`Run All`). O notebook instalar√° as depend√™ncias, executar√° o ETL completo e gerar√° todos os relat√≥rios e gr√°ficos na pasta `output/`.

## üìä Resultados e An√°lises Geradas

A √∫ltima etapa do notebook realiza uma s√©rie de an√°lises sobre a tabela final para demonstrar o seu valor. Os insights extra√≠dos incluem:

#### 1. Crescimento Exponencial de Lan√ßamentos da SpaceX
O gr√°fico de linhas mostra a evolu√ß√£o do n√∫mero de lan√ßamentos por ano, evidenciando o r√°pido crescimento das opera√ß√µes.

![Gr√°fico de Lan√ßamentos por Ano](notebooks/output/images/launches_per_year.png)

#### 2. Desempenho e Distribui√ß√£o por Pa√≠s
A an√°lise do n√∫mero de lan√ßamentos por pa√≠s mostra a concentra√ß√£o das opera√ß√µes nos Estados Unidos, com um alt√≠ssimo √≠ndice de sucesso.

![Gr√°fico de Lan√ßamentos por Pa√≠s](notebooks/output/images/launches_per_country.png)

#### 3. Bases de Lan√ßamento Mais Ativas
O gr√°fico de barras horizontais identifica as bases de lan√ßamento mais estrat√©gicas para a SpaceX, destacando os principais centros operacionais.

![Gr√°fico de Lan√ßamentos por Base](notebooks/output/images/launches_per_launchpad.png)

#### 4. Valida√ß√£o da Qualidade dos Dados
O relat√≥rio de qualidade confirma a integridade do nosso dataset final. O gr√°fico abaixo mostra o percentual de valores nulos por coluna, evidenciando que os dados cr√≠ticos para an√°lise est√£o completos e limpos.

![Relat√≥rio de Qualidade de Dados](notebooks/output/images/data_quality_null_ratio.png)

---

*Projeto desenvolvido por Arthur Rodrigues.*